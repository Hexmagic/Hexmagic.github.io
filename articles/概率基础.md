### 写在前面

首先说明本人概率并不精通,写的东西里面可能有描述不清甚至谬误的地方,如果发现了请指出我会进行改正，谢谢！

### 随机事件与概率

#### 随机试验

在自然界和人类活动中,新生婴儿可能是男也可能是女，马路上车辆的个数等这类事先无法预知结果的不确定现象称之为**随机现象**。概率论主要研究随机现象的规律性，为了研究事物的规律就要客观事物进行观察，观察过程叫做**随机试验**

随机试验有以下三个特点:

1. 相同条件下可以重复进行
2. 每次试验的记过不知一种，但是试验之前必须明确试验的所有结果
3. 每次试验将会出现什么结果是无法预知的

#### 随机事件和样本空间

随机事件是在随机试验中，可能出现也可能不出现，而在大量重复试验中具有某种规律性的事件叫做随机事件(简称事件)。随机事件通常用大写英文字母A、B、C等表示。随机试验中的每一个可能出现的试验结果称为这个试验的一个样本点，记作ωi。全体样本点组成的集合称为这个试验的样本空间，记作Ω．即Ω={ω1，ω2，…，ωn，…}。仅含一个样本点的随机事件称为基本事件，含有多个样本点的随机事件称为复合事件。

#### 概率的定义

在n次试验中，若果事件A出现$n_{A}$次，则称比值$\frac {n_{A}} {A}$为n次试验中事件A出现的频率.记作$f_{n}(A)=\frac {n_{A}} {n}$称为A发生的频数，随着实验次数n的增大，频率逐渐稳定到一个实数，这个实数称为事件A发生的概率。(其实你懂什么是概率，这就是一段比较绕的数学废话)

##### 概率的三大性质

1. 非负性:任意事件A有$P(A) \ge 0$
2. 规范性：$P(\Omega)=1$,必然事件发生的概率为1
3. 可列可加性，若$A_1,A_2,...,A_n$为两两互不相容的事件有$P(\cup_{i=1}^{\infty} A_i)=\Sigma_{i=1}^{ \infty }P(A_i)$

#### 条件概率

条件概率是在事件$A$发生的情况下事件$B$发生的概率，记作$P(B|A)$，由上面的定义可知

$P(B|A)=\frac {P(AB)}{P(A)}$

> P(AB)事件A和事件B同时发生的概率

#### 全概率公式与贝叶斯公式

##### 全概率公式

全概率公式是概率论中非常重要的一个公式

若事件A1，A2，…构成一个完备事件组且都有正概率，则对任意一个事件B，有如下公式成立：

$\begin{aligned}
    P(B)&=P(BA_1)+P(BA_2)+...+P(BA_n)\\
    &=P(B|A_1)P(A_1) + P(B|A_2)P(A_2) + ... + P(B|A_n)P(A_n)\\
    &=\Sigma_{i=1}^{n}P(A_i)P(B|A_i)
\end{aligned}$

**贝叶斯公式**

设$A_1,A_2,...,A_n$为样本空间$\Omega$的一个完备事件组，$P(A_i)>0\;(i=1,2,...,n)$,B为满足条件$P(B)>0$的任一事件，则

$P(A_i|B)=\frac {P(A_i)P(B|A_i)} {\Sigma_{i=1}^{n}P(A_i)P(B|A_i)}$

### 随机变量及分布

#### 什么是随机变量
首先说明：**随机变量其实是一个函数**，下面来看定义：在样本空间$\Omega$上实值函数$X=X(\omega),\omega \in \Omega$,则称$X(\omega)$为随机变量，简单记作$X$

可能看起来有点抽象，我们来看个例子：投掷一枚骰子出现的点数，我们知道该试验的样本空间$\Omega=\begin{Bmatrix}1点,2点,3点,4点,5点,6点\end{Bmatrix}$,那么:

$X=\left\{\begin{matrix}
1&点数为1  \\
2&点数为2  \\
3&点数为3  \\
4&点数为4  \\
5&点数为5  \\
6&点数为6  \\
\end{matrix}\right.$

那么$X$就可以看做空间$\Omega$上的一个随机变量，你也应该明白：**随机变量就是一个分段函数，它把样本中的样本点映射为常数值(常数值可以指定，譬如用77代表1点，88代表2点)**

#### 分布函数

想来看下定义：设$X$为随机变量，则称定义域为(-∞,+∞)的函数

$F(x)=P(X\le x)$

为随机变量的分布函数,似乎看起来有点不明白，其实不难，结合上面的随机变量举个例子

$F(2)\Leftrightarrow$ P(X\le 2)$\Leftrightarrow随机变量常数值小于等于2的概率\Leftrightarrow掷骰子点数小于等于2的概率$

#### 概率密度

若随机变量$X$的分布函数$F(X)$可以表示成非负可积函数$f(x)$的积分形式:

$F(X) = \int_{-\infty}^{x}f(t)dt,\;-\infty \lt x \lt +\infty$

则称函数$f(x)$为$X$的密度函数,看清楚了是$f(x)$不是$F(X)$

<!-- ##### 概率密度和分布函数相互转换 -->

> 对比密度函数$f(x)$和分布函数F(X)的定义可以发现:**分布函数是密度函数的原函数**,所以给定概率密度函数我们可以算出分布函数(直接求导即可),给定密度函数按照上面的例子可以求出对应的**分布函数**

#### 随机变量的分类

随机变量分为三类:
1. 离散型随机变量
2. 连续型随机变量
3. 混合型随机变量
最后一种是上面两种的混合,暂不研究

<!-- ##### 怎么判断离散还是连续?

举个例子什么随机变量是离散型的,什么样的随机变量是连续型的

例如掷骰子,它的随机变量取值是**有限个或者可列无穷多个**,那么它是一个离散型的随机变量,

**若对随机变量存在概率密度函数$f(x)$,则称随机变量$X$是连续型随机变量,**,有一个结论很重要,对于连续型随机变量$X$,P(X=任意常数)=0 -->

> 由上面我们可知离散型随机变量只有分布函数没有概率密度函数,而连续型随机变量两者都有

#### 分布律

分布律就是概率分布,另外分布律就是一张表格,如下面

|X|1|2|3|
|-|-|-|-|
|**P**|0.2|0.4|0.4|

第一行给出随机变量的所有取值,第二行给出随机变量对应各各个可能值得概率

> 连续型随机变量没有分布律

#### 常见分布

下面我们将会涉及六种常见分布:二项分布、泊松分布、几何分布、均匀分布、指数分布、正态分布

二项分布、泊松分布、几何分布是只有离散型随机变量才能服从的分布类型,均匀分布、指数分布、指数分布只有连续型随机变量才能服从

这里我不想每个分布再细讲,因为这不是概率论教程.我们只需要理解相关概念即可

#### 期望、方差、协方差、相关系数

> 期望和方差的公式太简单,我就不写了

##### 期望
在概率论和统计学中，数学期望（或均值，亦简称期望）是试验中每次可能结果的概率乘以其结果的总和。它反映随机变量平均取值的大小。一般用$E$代表

##### 方差

概率论中方差用来度量随机变量和其数学期望（即均值）之间的偏离程度,一般用$Var$代表

##### 协方差

协方差可以衡量两个变量直线的线性相关程度,一般用$Cov$表示,它的定义为:

$Con(x,y) = E((x-E(x))(y-E(y)))$


> 两个变量相互独立,它们的协方差为0

##### 相关系数

首先说明为什么引入相关系数:在变量$A$、$B$的取值标准和范围不同时候，协方差在数值上差异很大。
为了解决上述缺点，将协方差除以A的标准差和B的标准差，从而剔除上面的影响。这就是相关系数$Corr$

$Corr=\frac{Cov(x,y)}{\sqrt{Var(x)Var(y)}}$

> 相关系数值越接近1，说明两个变量正相关性越强。越接近-1，说明负相关性越强，当为0时，表示两个变量无线性相关

